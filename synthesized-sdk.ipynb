{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Li3IQXKJrcza"
   },
   "source": [
    "<img src=\"https://uploads-ssl.webflow.com/5f2d65b321549c3a6228ce06/60892a20edbd1da3fd641167_Synthesized%20logo.png\" width=\"350\" alt=\"Synthesized\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbPsT--Rjzkw"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the demo notebook, where we showcase some of the core features of the Synthesized SDK.\n",
    "\n",
    "You can apply the Synthesized SDK to automatically create a **general-purpose generative model** for any dataset, enabling easy solutions to a wide range of classic data problems.\n",
    "\n",
    "This notebook looks at 4 different examples:\n",
    "1. Bootstrap data where the density of data is low\n",
    "2. Automatically reshape data as you like\n",
    "3. Anonymise data for repurposing\n",
    "4. Identify biases in structured data **(Latest release!)**\n",
    " \n",
    "**Note:**\n",
    "\n",
    "If you want to save your progress and come back to your work in a new session you must copy this notebook to your Google Drive.\n",
    " \n",
    "If you wish to use the SDK outside Colab, in a production environment, on-premise/private cloud, connect to databases, integrate into ETL, work with Spark and big data sources natively, or just move beyond a single dataframe in memory,  get in touch with us on letschat@synthesized.io.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "[Synthesized Docs](https://docs.synthesized.io/latest/)\n",
    "\n",
    "[Sdk for data manipulation](https://www.synthesized.io/sdk-for-data-manipulation) \n",
    "\n",
    "[Contact us](letschat@synthesized.io)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GCctWNIkQ9c"
   },
   "source": [
    "\n",
    "# Synthesized License Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "AW3Vqy9gujY-"
   },
   "outputs": [],
   "source": [
    "#@title ### Request licence key\n",
    "#@markdown Please enter your details to receive a licence key. You will need to enter the licence key in order to run the notebook cells below.\n",
    "\n",
    "first_name = \"\" #@param {type:\"string\"}\n",
    "last_name = \"\" #@param {type:\"string\"}\n",
    "email = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Submit the form by running the cell (⌘/ctrl+Enter).\n",
    "import requests\n",
    "\n",
    "if email is None or len(email.split(\"@\")) < 2:\n",
    "  print(\"please enter a valid email\")\n",
    "else:\n",
    "  print(f\"An email has been sent to {email}\")\n",
    "  url = f'https://us-central1-synthesized-cloud-275014.cloudfunctions.net/process-licence-request?firstname={first_name}&lastname={last_name}&email={email}'\n",
    "  # payload = f'{{firstname: \"{first_name}\", lastname: \"{last_name}\", email: \"{email}\" }}'\n",
    "  r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "Lszz0jBc9hPe"
   },
   "outputs": [],
   "source": [
    "#@title ### Set the licence key\n",
    "#@markdown Please check you email for the licence key which can be pasted below:\n",
    "\n",
    "licence_key = \"\" #@param {type:\"string\"}\n",
    "\n",
    "import os\n",
    "os.environ[\"SYNTHESIZED_KEY\"] = licence_key\n",
    "print(f\"Set Synthesized licence key to {licence_key}.\")\n",
    "\n",
    "#@markdown The Synthesized SDK will be installed once you have entered the key and run this cell (⌘/ctrl+Enter).\n",
    "!pip install -q imgaug==0.2.5\n",
    "!pip install -q --pre \"synthesized[colab]>=1.5rc\" --extra-index https://colab:AP3DrAqXTX3dSMVAW1SwowpKgsh@synthesizedio.jfrog.io/artifactory/api/pypi/synthesized-colab/simple\n",
    "\n",
    "import synthesized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9acLAGTuuhJ"
   },
   "source": [
    "# Example 1 - Bootstrapping Data\n",
    "\n",
    "This workflow is one of the simplest and **it takes up to 4 minutes.**\n",
    "\n",
    "To create a generative model with the Synthesized SDK,  we will use the `HighDimSynthesizer` object from the library. But firstly, we need to extract all meta-information from the data frame, by calling `MetaExtractor.extract`, which will create a df_meta: `DataFrameMeta` object.\n",
    "\n",
    "Next we use df_meta to construct the `HighDimSynthesizer`, and when we call `synthesizer.learn()`, the `HighDimSynthesizer` learns patterns in the data it can later use for generation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI2QCoCMuv11"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from synthesized import HighDimSynthesizer, MetaExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvp02WFJuvq5"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('https://raw.githubusercontent.com/synthesized-io/synthesized-notebooks/master/data/claim_prediction.csv'); df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHKx9d_JvVrU"
   },
   "outputs": [],
   "source": [
    "# Extract the meta information from the dataset\n",
    "df1_meta = MetaExtractor.extract(df=df1)\n",
    "\n",
    "# Construct and train the generative model\n",
    "synth1 = HighDimSynthesizer(df1_meta)\n",
    "synth1.learn(df_train=df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQRxfgLCvXzy"
   },
   "outputs": [],
   "source": [
    "# Let's now create an additional 1000 rows\n",
    "df1_synth = synth1.synthesize(1000); df1_synth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVMekNV5mD7F"
   },
   "source": [
    "We can use the `Assessor` object to do a quick visual comparison of the newly generated data with the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyL_Icy_vXZq"
   },
   "outputs": [],
   "source": [
    "from synthesized.testing import Assessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NW9PkaUqvilr"
   },
   "outputs": [],
   "source": [
    "Assessor(df1_meta).show_distributions(df1, df1_synth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNpd645SvvPx"
   },
   "source": [
    "# Example 2 - Reshaping Data\n",
    "\n",
    "When creating a predictive model for imbalanced classification, one may encounter a number of pitfalls: some models are unsuitable, model explainability may suffer and unwanted biases may be propagated.\n",
    "\n",
    "To solve these problems, the Synthesized SDK enables fast and accurate rebalancing of datasets through conditional sampling of the generative model. With just two lines of extra code we can create a balanced dataset for model training!\n",
    "\n",
    "Here, the dataset used is a [public credit scoring dataset from Kaggle](https://www.kaggle.com/c/GiveMeSomeCredit/data).\n",
    "\n",
    "**Read more:**\n",
    "\n",
    "- Our [blog post](https://www.synthesized.io/post/solving-data-imbalance-with-synthetic-data) with a more in-depth analysis of a balanced dataset.\n",
    "- The [SDK documentation](https://docs.synthesized.io/latest/user_guide/conditions.html) for more ways to enhance and reshape your data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyPLm1D_uwkb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from synthesized import ConditionalSampler, HighDimSynthesizer, MetaExtractor\n",
    "from synthesized.insight.metrics import modelling_metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPXp2wYxuw4W"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('https://raw.githubusercontent.com/synthesized-io/synthesized-notebooks/master/data/credit.csv'); df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz87sZP_vRvj"
   },
   "outputs": [],
   "source": [
    "pms = metrics.PredictiveModellingScore('Linear', y_label='SeriousDlqin2yrs')\n",
    "print('Predictive Modelling ROC AUC', pms(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI2xB7o7w5ri"
   },
   "source": [
    "We've trained a model on the dataset to predict `'SeriousDlqin2yrs'` and evaluated its performance. Now lets use the generative model to improve that result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQMih-eUuxSP"
   },
   "outputs": [],
   "source": [
    "# Extract the meta information from the dataset\n",
    "df2_meta = MetaExtractor.extract(df2)\n",
    "\n",
    "# Construct and train the generative model\n",
    "synth2 = HighDimSynthesizer(df2_meta)\n",
    "synth2.learn(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuHJ_kiNv7tK"
   },
   "source": [
    "We train the generative model in the same manner as before. \n",
    "\n",
    "Once learned, we can then wrap it with a `ConditionalSampler` that can be queried to produce a new dataset with a balanced distribution of 'SeriousDlqin2yrs'. Our desired distribution is specified using the `explicit_marginals` parameter. We can then compare a classifier trained on the balanced data to the original classifer and also visualize the effect of reshaping the data using the `Assessor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_acACSH0oZws"
   },
   "outputs": [],
   "source": [
    "from synthesized import ConditionalSampler\n",
    "from synthesized.testing import Assessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5-MLGSun_Wv"
   },
   "outputs": [],
   "source": [
    "sampler = ConditionalSampler(synth2)\n",
    "df2_balanced = sampler.synthesize(num_rows=len(df2), explicit_marginals={'SeriousDlqin2yrs': [(0, 0.5), (1, 0.5)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxHX5WDgvpKb"
   },
   "outputs": [],
   "source": [
    "pmc = metrics.PredictiveModellingComparison('Linear', y_label='SeriousDlqin2yrs')\n",
    "\n",
    "# Greater than 1 -> the new datset produced a better result than the original dataset \n",
    "# when evaluated on some held out data.\n",
    "print('Ratio of ROC AUC using df2_balanced / df2', pmc(df2, df2_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdqLYxgIomP1"
   },
   "outputs": [],
   "source": [
    "Assessor(df2_meta).show_distributions(df2, df2_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_koRfpfkux-i"
   },
   "source": [
    "# Example 3 - Data Anonymization\n",
    "\n",
    "The privacy needs for each user and application are different, so we wanted to give you  flexibility to increase the amount of information that can be extracted from the original dataset by adding a Differential Privacy training option to the model.\n",
    "\n",
    "A privacy evaluation module is also provided as part of the SDK, to ensure the privacy needs of each user are achieved. This colab version of the SDK contains a small subset of the available metrics and evaluations to conduct some preliminary privacy assessments.\n",
    "\n",
    "Here, we compare how robust is generative modelling  with Differential Privacy against an attribute inference attack. The dataset is a [German Credit Dataset from Kaggle](https://www.kaggle.com/uciml/german-credit).\n",
    "\n",
    "\n",
    "**Read more:** \n",
    "- Docs about [differential privacy](https://docs.synthesized.io/latest/user_guide/privacy/differential_privacy.html) and [privacy assessment](https://docs.synthesized.io/latest/user_guide/evaluation/privacy.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Po9n6WOuuye2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from synthesized import MetaExtractor, HighDimSynthesizer\n",
    "from synthesized.config import HighDimConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXNP0jzjuy2D"
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"https://raw.githubusercontent.com/synthesized-io/synthesized-notebooks/staging/data/german_credit_data.csv\"); df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPsjaJ-IwJ9h"
   },
   "source": [
    "Below, we train two synthesizers, one with default configuration and the second one with Differential Privacy enabled, and we sample datasets for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DImy7gq0wOBw"
   },
   "outputs": [],
   "source": [
    "df3_meta = MetaExtractor.extract(df3)\n",
    "\n",
    "# Learn and synthesize the dataset with default configuration\n",
    "synth3 = HighDimSynthesizer(df3_meta)\n",
    "synth3.learn(df3)\n",
    "df3_synth = synth3.synthesize(len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhzkLd-uwRxS"
   },
   "outputs": [],
   "source": [
    "# Learn and synthesize the dataset with Differential Privacy\n",
    "synth3_dp = HighDimSynthesizer(df3_meta, config=HighDimConfig(differential_privacy=True))\n",
    "synth3_dp.learn(df3)\n",
    "df3_synth_dp = synth3_dp.synthesize(len(df3)); df3_synth_dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANvbJicIwdH8"
   },
   "outputs": [],
   "source": [
    "from synthesized.insight.metrics import privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCxHb6kEwg4i"
   },
   "outputs": [],
   "source": [
    "metric = privacy.AttributeInferenceAttackML(\n",
    "    model='GradientBoosting', \n",
    "    sensitive_col='Credit amount',\n",
    "    predictors=['Age', 'Sex', 'Housing']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqWVmidL_jXl"
   },
   "outputs": [],
   "source": [
    "print(metric(df3, df3_synth))\n",
    "print(metric(df3, df3_synth_dp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikLMVBb-8KNo"
   },
   "source": [
    "# Example 4 - Data bias (New!)\n",
    "\n",
    "With the recent release of [Fairlens](https://github.com/synthesized-io/fairlens) we can now make some measurements of some biases within datasets.\n",
    "\n",
    "We can use the SDK to upsample rare groups the data in order to check for other biases that may be hidden.\n",
    "\n",
    "The full version of the SDK offers the ability to mitigate the biases that are detected whilst preserving the other properties of the dataset.\n",
    "\n",
    "For this example we use [the COMPAS dataset](https://github.com/propublica/compas-analysis/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KtkQFwl8m7b"
   },
   "outputs": [],
   "source": [
    "# install the fairlens library\n",
    "! pip install -q fairlens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDOLMDzX9KWu"
   },
   "outputs": [],
   "source": [
    "import fairlens as fl\n",
    "import pandas as pd\n",
    "from synthesized import ConditionalSampler, HighDimSynthesizer, MetaExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLp_q9H29AYZ"
   },
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"https://raw.githubusercontent.com/synthesized-io/fairlens/main/datasets/compas.csv\"); df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5la14EF9W53"
   },
   "outputs": [],
   "source": [
    "fs = fl.FairnessScorer(df4, 'RawScore')\n",
    "fs.demographic_report()\n",
    "fs.plot_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4Oji94W9z05"
   },
   "outputs": [],
   "source": [
    "df4_meta = MetaExtractor.extract(df4)\n",
    "synth4 = HighDimSynthesizer(df4_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19Fok9Ro-da_"
   },
   "outputs": [],
   "source": [
    "synth4.learn(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcTUniiy-dUO"
   },
   "outputs": [],
   "source": [
    "sampler = ConditionalSampler(synth4)\n",
    "df4_balanced = sampler.synthesize(num_rows=len(df4), explicit_marginals={'Sex': [('Male', 0.5), ('Female', 0.5)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xlJ7GUj-dJ1"
   },
   "outputs": [],
   "source": [
    "fs_balanced = fl.FairnessScorer(df4_balanced, 'RawScore')\n",
    "fs_balanced.demographic_report()\n",
    "fs_balanced.plot_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhQAn6Br9hPt"
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "While this notebook is focused on just some of the many benefits of generative models, it gives you a glimpse into how you can quickly start leveraging the SDK in development and testing of machine learning models and beyond.\n",
    "\n",
    "You can learn about other features of the Synthesized SDK [in the Docs](https://docs.synthesized.io/latest/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l6W_Kjarczb"
   },
   "source": [
    "### Licence Agreement\n",
    "\n",
    "Please note that your use of this colab environment is subject to the following terms and policies:\n",
    "* https://www.synthesized.io/privacy-policy\n",
    "* https://www.synthesized.io/data-processing-addendum\n",
    "* https://www.synthesized.io/terms-of-service\n",
    "* https://support.google.com/drive/answer/2450387?hl=en"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "synthesized-sdk.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
