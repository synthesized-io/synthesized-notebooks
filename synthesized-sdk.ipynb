{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "synthesized-sdk.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li3IQXKJrcza"
      },
      "source": [
        "<img src=\"https://uploads-ssl.webflow.com/5f2d65b321549c3a6228ce06/60892a20edbd1da3fd641167_Synthesized%20logo.png\" width=\"350\" alt=\"Synthesized\" align=\"left\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbPsT--Rjzkw"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Welcome to the demo notebook, where we showcase some of the core features of the Synthesized SDK.\n",
        "\n",
        "You can apply the Synthesized SDK to automatically create a **general-purpose generative model** for any dataset. The generative model then enables easy solutions to a wide range of classic data problems.\n",
        "\n",
        "This notebook looks at 4 different use cases:\n",
        "\n",
        "1.  Bootstrap data where the density of data is low\n",
        "2.  Automatically reshape data as you like \n",
        "3.  Anonymise data for repurposing\n",
        "4.  Explore signals of bias in an unfair dataset **(New!)**\n",
        "\n",
        "Of course, there are countless doors unlocked once you equip your dataset with a generative model. You can learn about some of these other features of the Synthesized SDK [in the Docs](https://docs.synthesized.io/v1.4/). \n",
        "\n",
        "**Note: This is a Google Colab version of the SDK.** In order to use the SDK outside Colab in a production environment, on-premise/private cloud, connect to databases, intergrate into ETL, being able to work with Spark and big data sources natively, or just moving beyond a single dataframe in memory and more reach out to letschat@synthesized.io for a commercial version of the SDK. You can read more about it here http://synthesized.io/sdk-for-data-manipulation.\n",
        "\n",
        "**Note: If you want to you save your progress and come back to your work in a new session you must copy this notebook to your Google Drive.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GCctWNIkQ9c"
      },
      "source": [
        "\n",
        "# Synthesized License Key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lszz0jBc9hPe",
        "cellView": "form"
      },
      "source": [
        "#@title ### Install Synthesized\n",
        "#@markdown This cell will grab you a licence key and install the Synthesized python SDK.\n",
        "\n",
        "#@markdown Install with `⌘/ctrl+Enter`\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# url = f'https://us-central1-synthesized-cloud-275014.cloudfunctions.net/free-licence-request'\n",
        "# licence_key = requests.get(url)\n",
        "licence_key = \"SmRvOG1TbGF6MnRRNU5KMkZneFZQQ09wTWZpNGhQTjlCaUpRSnV5SWU3K011dlJmZ3QrRFZ2eWhYbGszQmM3MWFTeUtVVjJKd3ptRSszcTJaL2x4amc9PXsiZXhwaXJ5IjogIjIwMjMtMDctMjgiLCAiZmVhdHVyZV9pZHMiOiBbIioiXSwgImNvbGFiIjogdHJ1ZX0=\"\n",
        "\n",
        "os.environ[\"SYNTHESIZED_KEY\"] = licence_key\n",
        "print(f\"Set Synthesized licence key to {licence_key}.\")\n",
        "\n",
        "!pip install -q imgaug==0.2.5\n",
        "!pip install -q synthesized==1.4 --extra-index https://colab:AP3DrAqXTX3dSMVAW1SwowpKgsh@synthesizedio.jfrog.io/artifactory/api/pypi/synthesized-colab/simple\n",
        "\n",
        "import synthesized\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9acLAGTuuhJ"
      },
      "source": [
        "# Use Case 1 - Bootstrapping Data\n",
        "\n",
        "This workflow is one of the simplest. In all of these workflows we use the `HighDimSynthesizer` object from the library. This is a key object for creating a generative model with the Synthesized SDK. Before using it, we need to extract all meta-information from the dataframe. This is done by calling `MetaExtractor.extract`, which will create a `df_meta: DataFrameMeta` object.\n",
        "\n",
        "Next we use `df_meta` to create a `synthesizer: HighDimSynthesizer`, and then when we call `synthesizer.learn()` . The HighDimSynthesizer learns patterns in the data it can later use for generation.\n",
        "**This  step takes approximately 4 minutes.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI2QCoCMuv11"
      },
      "source": [
        "import pandas as pd\n",
        "from synthesized import HighDimSynthesizer, MetaExtractor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvp02WFJuvq5"
      },
      "source": [
        "df1 = pd.read_csv('https://raw.githubusercontent.com/synthesized-io/synthesized-notebooks/master/data/claim_prediction.csv'); df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHKx9d_JvVrU"
      },
      "source": [
        "# Extract the meta information from the dataset\n",
        "df1_meta = MetaExtractor.extract(df=df1)\n",
        "\n",
        "# Construct and train the generative model\n",
        "synth1 = HighDimSynthesizer(df1_meta)\n",
        "synth1.learn(df_train=df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQRxfgLCvXzy"
      },
      "source": [
        "# Let's now create an additional 1000 rows\n",
        "df1_synth = synth1.synthesize(1000); df1_synth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVMekNV5mD7F"
      },
      "source": [
        "We can use the `Assessor` object to do a quick visual comparison of the newly generated data with the original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyL_Icy_vXZq"
      },
      "source": [
        "from synthesized.testing import Assessor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW9PkaUqvilr"
      },
      "source": [
        "Assessor(df1_meta).show_distributions(df1, df1_synth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNpd645SvvPx"
      },
      "source": [
        "# Use Case 2 - Reshaping Data\n",
        "\n",
        "When creating a predictive model for imbalanced classification, one may encounter a number of pitfalls: some models are unsuitable, model explainability may suffer and unwanted biases may be propagated.\n",
        "\n",
        "To solve this problem, the Synthesized SDK enables fast and accurate rebalancing of datasets through conditional sampling of the generative model. With just two lines of extra code we can create a balanced dataset for model training!\n",
        "\n",
        "See our [blog post](https://www.synthesized.io/post/solving-data-imbalance-with-synthetic-data) for a more in-depth analysis of a balanced dataset, and check out the [SDK documentation](https://docs.synthesized.io/v1.4/user_guide/augmentation/index.html) to see more ways to enhance and reshape your data. \n",
        "\n",
        "Here, the dataset used is a [public credit scoring dataset from Kaggle](https://www.kaggle.com/c/GiveMeSomeCredit/data).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyPLm1D_uwkb"
      },
      "source": [
        "import pandas as pd\n",
        "from synthesized import ConditionalSampler, HighDimSynthesizer, MetaExtractor\n",
        "from synthesized.insight.metrics import modelling_metrics as metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPXp2wYxuw4W"
      },
      "source": [
        "df2 = pd.read_csv('https://raw.githubusercontent.com/synthesized-io/synthesized-notebooks/master/data/credit.csv'); df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz87sZP_vRvj"
      },
      "source": [
        "pms = metrics.PredictiveModellingScore('Linear', y_label='SeriousDlqin2yrs')\n",
        "print('Predictive Modelling ROC AUC', pms(df2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI2xB7o7w5ri"
      },
      "source": [
        "We've trained a model on the dataset to predict `'SeriousDlqin2yrs'` and evaluated its performance. Now lets use synthetic data to improve that result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQMih-eUuxSP"
      },
      "source": [
        "# Extract the meta information from the dataset\n",
        "df2_meta = MetaExtractor.extract(df2)\n",
        "\n",
        "# Construct and train the generative model\n",
        "synth2 = HighDimSynthesizer(df2_meta)\n",
        "synth2.learn(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuHJ_kiNv7tK"
      },
      "source": [
        "We train the generative model in the same manner as before. Once learned, we can then wrap it with a `ConditionalSampler` that can be queried to produce a new dataset with a balanced distribution of 'SeriousDlqin2yrs'. Our desired distribution is specified using the `explicit_marginals` parameter. We can then compare a classifier trained on the balanced data to the original classifer and also visualize the effect of reshaping the data using the `Assessor`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_acACSH0oZws"
      },
      "source": [
        "from synthesized import ConditionalSampler\n",
        "from synthesized.testing import Assessor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5-MLGSun_Wv"
      },
      "source": [
        "sampler = ConditionalSampler(synth2)\n",
        "df2_balanced = sampler.synthesize(num_rows=len(df2), explicit_marginals={'SeriousDlqin2yrs': {'0': 0.5, '1': 0.5}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxHX5WDgvpKb"
      },
      "source": [
        "pmc = metrics.PredictiveModellingComparison('Linear', y_label='SeriousDlqin2yrs')\n",
        "\n",
        "# Greater than 1 -> the new datset produced a better result than the original dataset \n",
        "# when evaluated on some held out data.\n",
        "print('Ratio of ROC AUC using df2_balanced / df2', pmc(df2, df2_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdqLYxgIomP1"
      },
      "source": [
        "Assessor(df2_meta).show_distributions(df2, df2_balanced)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_koRfpfkux-i"
      },
      "source": [
        "# Use Case 3 - Privacy\n",
        "\n",
        "At Synthesized we understand that the privacy needs for each user and application are different, so we give the user flexibility to increase the amount of information that can be extracted from the original dataset by adding a Differential Privacy training option to the model.\n",
        "\n",
        "A privacy evaluation module is also provided as part of the SDK, to ensure the privacy needs of each user are achieved. This colab version of the SDK contains a small subset of the available metrics and evaluations to conduct some preliminary privacy assessments.\n",
        "\n",
        "Read more about [differential privacy](https://docs.synthesized.io/v1.4/user_guide/augmentation/differential_privacy.html) and [privacy assesment](https://docs.synthesized.io/v1.4/user_guide/evaluation/privacy.html) in our documentation.\n",
        "\n",
        "Here, we compare how robust are Synthesized and Synthesized with Differential Privacy against an attribute inference attack. The dataset is a [German Credit Dataset from Kaggle](https://www.kaggle.com/uciml/german-credit)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po9n6WOuuye2"
      },
      "source": [
        "import pandas as pd\n",
        "from synthesized import MetaExtractor, HighDimSynthesizer\n",
        "from synthesized.config import HighDimConfig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXNP0jzjuy2D"
      },
      "source": [
        "df3 = pd.read_csv(\"https://raw.githubusercontent.com/synthesized-io/synthesized-notebooks/staging/data/german_credit_data.csv\"); df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPsjaJ-IwJ9h"
      },
      "source": [
        "Below, we train two synthesizers, one with default configuration and the second one with Differential Privacy enabled, and we sample datasets for both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DImy7gq0wOBw"
      },
      "source": [
        "df3_meta = MetaExtractor.extract(df3)\n",
        "\n",
        "# Learn and synthesize the dataset with default configuration\n",
        "synth3 = HighDimSynthesizer(df3_meta)\n",
        "synth3.learn(df3)\n",
        "df3_synth = synth3.synthesize(len(df3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhzkLd-uwRxS"
      },
      "source": [
        "# Learn and synthesize the dataset with Differential Privacy\n",
        "synth3_dp = HighDimSynthesizer(df3_meta, config=HighDimConfig(differential_privacy=True))\n",
        "synth3_dp.learn(df3)\n",
        "df3_synth_dp = synth3_dp.synthesize(len(df3)); df3_synth_dp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_87ryk3wVAU"
      },
      "source": [
        "In this example, the user has access to three columns from the original dataset, 'Age', 'Sex' and 'Housing', and will try to disclose information about 'Credit amount'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANvbJicIwdH8"
      },
      "source": [
        "from synthesized.insight.metrics import privacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCxHb6kEwg4i"
      },
      "source": [
        "metric = privacy.AttributeInferenceAttackML(\n",
        "    model='GradientBoosting', \n",
        "    sensitive_col='Credit amount',\n",
        "    predictors=['Age', 'Sex', 'Housing']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqWVmidL_jXl"
      },
      "source": [
        "print(metric(df3, df3_synth))\n",
        "print(metric(df3, df3_synth_dp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikLMVBb-8KNo"
      },
      "source": [
        "# Use Case 4 - Fairness (New!)\n",
        "\n",
        "With the recent release of [our open source library, fairlens](https://github.com/synthesized-io/fairlens) we can now make some measurements of some biases within datasets.\n",
        "\n",
        "We can use the SDK to upsample rare groups the data in order to check for other biases that may be hidden.\n",
        "\n",
        "The full version of the SDK offers the ability to mitigate the biases that are detected whilst preserving the other properties of the dataset.\n",
        "\n",
        "For this example we use [the COMPAS dataset](https://github.com/propublica/compas-analysis/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KtkQFwl8m7b"
      },
      "source": [
        "# install the fairlens library\n",
        "! pip install -q fairlens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDOLMDzX9KWu"
      },
      "source": [
        "import fairlens as fl\n",
        "import pandas as pd\n",
        "from synthesized import ConditionalSampler, HighDimSynthesizer, MetaExtractor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLp_q9H29AYZ"
      },
      "source": [
        "df4 = pd.read_csv(\"https://raw.githubusercontent.com/synthesized-io/fairlens/main/datasets/compas.csv\"); df4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5la14EF9W53"
      },
      "source": [
        "fs = fl.FairnessScorer(df4, 'RawScore')\n",
        "fs.demographic_report()\n",
        "fs.plot_distributions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4Oji94W9z05"
      },
      "source": [
        "df4_meta = MetaExtractor.extract(df4)\n",
        "synth4 = HighDimSynthesizer(df4_meta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Fok9Ro-da_"
      },
      "source": [
        "synth4.learn(df4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcTUniiy-dUO"
      },
      "source": [
        "sampler = ConditionalSampler(synth4)\n",
        "df4_balanced = sampler.synthesize(num_rows=len(df4), explicit_marginals={'Sex': {'Male': 0.5, 'Female': 0.5}})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xlJ7GUj-dJ1"
      },
      "source": [
        "fs_balanced = fl.FairnessScorer(df4_balanced, 'RawScore')\n",
        "fs_balanced.demographic_report()\n",
        "fs_balanced.plot_distributions()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhQAn6Br9hPt"
      },
      "source": [
        "# Conclusions\n",
        "\n",
        "While this notebook is focused on just some of the many benefits of generative models we've designed, we hope it showcases how you can quickly start levaraging the SDK in development and testing of machine learning models and beyond. \n",
        "\n",
        "You can learn about other features of the Synthesized SDK [in the Docs](https://docs.synthesized.io/v1.4/). \n",
        "\n",
        "**Note: This is a Google Colab version of the SDK.** In order to use the SDK outside Colab in a production environment, on-premise/private cloud, connect to databases, intergrate into ETL, being able to work with Spark and big data sources natively, or just moving beyond a single dataframe in memory and more reach out to letschat@synthesized.io for a commercial version of the SDK. You can read more about it here http://synthesized.io/sdk-for-data-manipulation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjDOcfiIwz3q"
      },
      "source": [
        "# How can synthetic data help you?\n",
        "Have a try below and let us know! Our documentation is available at https://docs.synthesized.io/v1.4/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZsl1o-ew71D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nauuKnvw7va"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke9r91Hsw7k2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l6W_Kjarczb"
      },
      "source": [
        "### Licence Agreement\n",
        "\n",
        "Please note that your use of this colab environment is subject to the following terms and policies:\n",
        "* https://www.synthesized.io/privacy-policy\n",
        "* https://www.synthesized.io/data-processing-addendum\n",
        "* https://www.synthesized.io/terms-of-service\n",
        "* https://support.google.com/drive/answer/2450387?hl=en"
      ]
    }
  ]
}